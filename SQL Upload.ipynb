{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "PATH = config.PATH\n",
    "db = mysql.connector.connect(\n",
    "    host=config.host,\n",
    "    user=config.user,\n",
    "    passwd=config.passwd,\n",
    "    database=config.database\n",
    ")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_choice(list):\n",
    "    return list[random.randrange(0, len(list))]\n",
    "\n",
    "def rand_date(start, end, format, prop):\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(format, time.localtime(ptime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading users\n",
    "## We have | User ID | First Name | Last Name | Gender |  Home Town | City |\n",
    "## We don't have | Relationship Status |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID FirstName   LastName  Gender          Hometown            City\n",
      "0       1   Phillip  Alldridge    Male   North Amayatown     Jermeymouth\n",
      "1       2     Logan     Norris  Female       Reichelland    East Daphnee\n",
      "2       3     Holly      Grant  Female       Wuckertberg       Jamirfurt\n",
      "3       4  Chadwick    Gardner    Male  New Justinaville     West Manley\n",
      "4       5      Bart     Fenton    Male     South Zackery  New Dimitriton\n"
     ]
    }
   ],
   "source": [
    "## 00 single, 01 Engaged, 10 Married, 11 Complicated\n",
    "relationship_types = [int('00', base = 2), int('01', base = 2), int('10', base = 2), int('11', base = 2)]\n",
    "\n",
    "df = pd.read_csv(PATH + 'facebook_users_5000_max.csv')\n",
    "\n",
    "print(df.head())\n",
    "for index, row in df.iterrows():\n",
    "    # Only male or female in the dataset, but using 2 BITS so 10 = unspecified\n",
    "    gender = int('00', base = 2) if row['Gender'] == 'Male' else int('01', base = 2)\n",
    "    #Random choice for a relationship status\n",
    "    relationship_status = rand_choice(relationship_types)\n",
    "    sql = \"INSERT INTO Users (userID, firstName, lastName, gender, homeTown, currentCity, relationshipStatus) VALUES ({0}, \\\"{1}\\\", \\\"{2}\\\", {3}, \\\"{4}\\\", \\\"{5}\\\", {6});\".format(\n",
    "    row['UserID'], row['FirstName'], row['LastName'], gender, row['Hometown'], row['City'], relationship_status)\n",
    "    cursor.execute(sql)\n",
    "    #print(sql)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Workplaces\n",
    "## We have the name and the ID is auto incrementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID         Workplace\n",
      "0       1             AECOM\n",
      "1       2               NaN\n",
      "2       3  21st Century Fox\n",
      "3       3        Apple Inc.\n",
      "4       3  Metro Cash&Carry\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'workplace.csv')\n",
    "\n",
    "# Key value list {work place name : work place id}\n",
    "workplaces_dict = {}\n",
    "num_workplaces = 0\n",
    "print(df.head())\n",
    "for index, row in df.iterrows():\n",
    "    if row['Workplace'] not in workplaces_dict and not pd.isna(row['Workplace']):\n",
    "        num_workplaces += 1\n",
    "        workplaces_dict.update({row['Workplace'] : num_workplaces})\n",
    "        sql = \"INSERT INTO Workplaces(workplaceName) VALUES(\\\"{0}\\\");\".format(row['Workplace'])\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "        #print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Worker\n",
    "## We have | User ID | Workplace ID |\n",
    "## We don't have | Start date | End date | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID         Workplace date_started date_left\n",
      "0       1             AECOM           []        []\n",
      "1       2               NaN           []        []\n",
      "2       3  21st Century Fox           []        []\n",
      "3       3        Apple Inc.           []        []\n",
      "4       3  Metro Cash&Carry           []        []\n",
      "      UserID   Workplace date_started date_left\n",
      "6893    4996  ExxonMobil           []        []\n",
      "6894    4997         NaN           []        []\n",
      "6895    4998         NaN           []        []\n",
      "6896    4999         NaN           []        []\n",
      "6897    5000         NaN           []        []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'workplace.csv')\n",
    "df['date_started'] = np.empty((len(df), 0)).tolist()\n",
    "df['date_left'] = np.empty((len(df), 0)).tolist()\n",
    "date_format = '%Y-%m-%d'\n",
    "\n",
    "# Drop any user over 5,000 - Data file has been made smaller to lower load on uni servers\n",
    "workerIndex = df[df['UserID'] > 5000].index\n",
    "df.drop(workerIndex , inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not pd.isna(row['Workplace']):\n",
    "        if row['UserID'] == df.iloc[index - 1, 0]:\n",
    "            df.iloc[index, 2] = rand_date(df.iloc[index - 1, 3], \"2020-1-1\", date_format, random.random())\n",
    "        else:\n",
    "            df.iloc[index, 2] = rand_date(\"1980-1-1\", \"2020-1-1\", date_format, random.random())\n",
    "        if row['UserID'] == df.iloc[index + 1, 0]:\n",
    "            df.iloc[index, 3] = rand_date(df.iloc[index, 2], \"2020-1-1\", date_format, random.random())\n",
    "        #Fetch the updated row\n",
    "        curr_row = df.iloc[index, :]\n",
    "        sql = \"\"\n",
    "        if curr_row['date_left'] == []:\n",
    "            sql = \"INSERT INTO Workers (userID, workplaceID, dateStarted) VALUES({0}, {1}, \\\"{2}\\\");\".format(\n",
    "            curr_row['UserID'], workplaces_dict[curr_row['Workplace']], curr_row['date_started'])\n",
    "        else:\n",
    "            sql = \"INSERT INTO Workers (userID, workplaceID, dateStarted, dateLeft) VALUES({0}, {1}, \\\"{2}\\\", \\\"{3}\\\");\".format(\n",
    "            curr_row['UserID'], workplaces_dict[curr_row['Workplace']], curr_row['date_started'], curr_row['date_left'])\n",
    "        cursor.execute(sql)\n",
    "        #print(sql)\n",
    "        db.commit()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Universities\n",
    "## We have the name and the ID is auto incrementing\n",
    "## Pretty much a copy and paste of Workplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID                     University\n",
      "0       1                            NaN\n",
      "1       2         University of Oklahoma\n",
      "2       2         University of Virginia\n",
      "3       3  University of Texas at Austin\n",
      "4       4     University at Buffalo SUNY\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'universities.csv')\n",
    "\n",
    "universities_dict = {}\n",
    "num_unis = 0\n",
    "print(df.head())\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['University'] not in universities_dict and not pd.isna(row['University']):\n",
    "        num_unis += 1\n",
    "        universities_dict.update({row['University'] : num_unis})\n",
    "        sql = \"INSERT INTO Universities(universityName) VALUES(\\\"{0}\\\");\".format(row['University'])\n",
    "        #print(sql)\n",
    "        cursor.execute(sql)\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Students\n",
    "## We have | User ID | universityName Name |\n",
    "## We don't have | Start date | End date | \n",
    "## Pretty much a full copy of Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID                     University date_started date_left\n",
      "0       1                            NaN           []        []\n",
      "1       2         University of Oklahoma           []        []\n",
      "2       2         University of Virginia           []        []\n",
      "3       3  University of Texas at Austin           []        []\n",
      "4       4     University at Buffalo SUNY           []        []\n",
      "      UserID                University date_started date_left\n",
      "6863    4996                       NaN           []        []\n",
      "6864    4997                       NaN           []        []\n",
      "6865    4998  University of Pittsburgh           []        []\n",
      "6866    4999                       NaN           []        []\n",
      "6867    5000                       NaN           []        []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'universities.csv')\n",
    "df['date_started'] = np.empty((len(df), 0)).tolist()\n",
    "df['date_left'] = np.empty((len(df), 0)).tolist()\n",
    "date_format = '%Y-%m-%d'\n",
    "\n",
    "# Drop any user over 5,000 - Data file has been made smaller to lower load on uni servers\n",
    "studentIndex = df[df['UserID'] > 5000].index\n",
    "df.drop(studentIndex , inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not pd.isna(row['University']):\n",
    "        if row['UserID'] == df.iloc[index - 1, 0]:\n",
    "            df.iloc[index, 2] = rand_date(df.iloc[index - 1, 3], \"2020-1-1\", date_format, random.random())\n",
    "        else:\n",
    "            df.iloc[index, 2] = rand_date(\"1980-1-1\", \"2020-1-1\", date_format, random.random())\n",
    "        if row['UserID'] == df.iloc[index + 1, 0]:\n",
    "            df.iloc[index, 3] = rand_date(df.iloc[index, 2], \"2020-1-1\", date_format, random.random())\n",
    "        #Fetch the updated row\n",
    "        curr_row = df.iloc[index, :]\n",
    "        sql = \"\"\n",
    "        if curr_row['date_left'] == []:\n",
    "            sql = \"INSERT INTO Students (userID, uniID, dateStarted) VALUES({0}, {1}, \\\"{2}\\\");\".format(\n",
    "            curr_row['UserID'], universities_dict[curr_row['University']], curr_row['date_started'])\n",
    "        else:\n",
    "            sql = \"INSERT INTO Students (userID, uniID, dateStarted, dateLeft) VALUES({0}, {1}, \\\"{2}\\\", \\\"{3}\\\");\".format(\n",
    "            curr_row['UserID'], universities_dict[curr_row['University']], curr_row['date_started'], curr_row['date_left'])\n",
    "        #print(sql)\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Friendships\n",
    "## No data to create here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID_1  UserID_2\n",
      "0         1         2\n",
      "1         1         3\n",
      "2         1         4\n",
      "3         1         5\n",
      "4         1         6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'facebook-friendships-5000_max.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = \"INSERT INTO Friendships(userID_1, userID_2) VALUES ({0}, {1});\".format(\n",
    "    row['UserID_1'], row['UserID_2'])\n",
    "    #print(sql)\n",
    "    cursor.execute(sql)\n",
    "    db.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Messages\n",
    "## No data to create here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID_1  UserID_2            Date_Time  \\\n",
      "0         1         2  2018-12-27 11:36:41   \n",
      "1         1         5  2018-10-12 03:12:01   \n",
      "2         1         9  2018-10-18 23:26:43   \n",
      "3         1        16  2018-12-29 08:33:17   \n",
      "4         1        20  2019-01-04 16:11:44   \n",
      "\n",
      "                                             Message  \n",
      "0  risus semper porta volutpat quam pede lobortis...  \n",
      "1  lectus pellentesque eget nunc donec quis orci ...  \n",
      "2  iaculis diam erat fermentum justo nec condimen...  \n",
      "3                                      morbi a ipsum  \n",
      "4  erat vestibulum sed magna at nunc commodo plac...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH + 'messages.csv')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "indexMessages = df[df['UserID_1'] > 5000].index\n",
    "df.drop(indexMessages , inplace=True)\n",
    "\n",
    "indexMessages = df[df['UserID_2'] > 5000].index\n",
    "df.drop(indexMessages , inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sql = \"INSERT INTO Messages(senderID, recipientID, sentTime, messageText) VALUES({0}, {1}, \\\"{2}\\\", \\\"{3}\\\");\".format(\n",
    "    row['UserID_1'], row['UserID_2'], row['Date_Time'], row['Message'])\n",
    "    cursor.execute(sql)\n",
    "    #print(sql)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done uploading the data!\n",
    "## How long it took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7260.322409152985\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
